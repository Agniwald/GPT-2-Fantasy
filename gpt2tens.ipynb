{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "99e007af3b4d429ea1ab50b719cc0088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e917e99e95846bda4967d58384ca20d",
              "IPY_MODEL_64827778c1824171a8b689e133c84eb6",
              "IPY_MODEL_77e5fab1a0574064bbbff0db8385c17e"
            ],
            "layout": "IPY_MODEL_5731bd1192ac4756b22096ac30af8249"
          }
        },
        "5e917e99e95846bda4967d58384ca20d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba464780c7574a41a88fe63ac071edfb",
            "placeholder": "​",
            "style": "IPY_MODEL_601ad4778bcf48f29ef6d243dbd00d8c",
            "value": "Map: 100%"
          }
        },
        "64827778c1824171a8b689e133c84eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b7be152b2b642218b95d5e6be532f38",
            "max": 6541,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12f8b64d25f84805ad7031cce06385a1",
            "value": 6541
          }
        },
        "77e5fab1a0574064bbbff0db8385c17e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d41c32fc5fae4b3c984ceef8480d3752",
            "placeholder": "​",
            "style": "IPY_MODEL_4a613bb7efbc405cb60a5137d3a820ea",
            "value": " 6541/6541 [00:35&lt;00:00, 234.21 examples/s]"
          }
        },
        "5731bd1192ac4756b22096ac30af8249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "ba464780c7574a41a88fe63ac071edfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "601ad4778bcf48f29ef6d243dbd00d8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b7be152b2b642218b95d5e6be532f38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12f8b64d25f84805ad7031cce06385a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d41c32fc5fae4b3c984ceef8480d3752": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a613bb7efbc405cb60a5137d3a820ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "id": "-0axjXV4WZJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hiM3zs8K6Ft"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
        "import pandas as pd\n",
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em8j8NfZY3Fu",
        "outputId": "c5b7a1fa-23f6-4c05-f766-d92fe548fd56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/AI/plot2tag_encoded_6500.csv\", header=None, sep='\\t')\n",
        "df.columns = ['text']\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "GLq_SHndZCjr",
        "outputId": "0e2c6941-a9e4-48f4-8294-15a92591093c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text\n",
              "0     ~^monster^frankenstein's monster^mirror^alchem...\n",
              "1     ~^monster^frankenstein's monster^mirror^alchem...\n",
              "2     ~^monster^frankenstein's monster^mirror^alchem...\n",
              "3     ~^monster^frankenstein's monster^mirror^alchem...\n",
              "4     ~^monster^frankenstein's monster^mirror^alchem...\n",
              "...                                                 ...\n",
              "6536  ~^parenthood^psychodrama^human animal hybrid^b...\n",
              "6537  ~^snow adventure^~@The sequel on the big scree...\n",
              "6538  ~^witch^sorceress^magic^supernatural killer^us...\n",
              "6539  ~^pokemon^~@A story of young adults who are on...\n",
              "6540  ~^snow^~@A thick layer of fresh snow provides ...\n",
              "\n",
              "[6541 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d5c100b-6ea8-41b3-982d-c3e4581d1a53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>~^monster^frankenstein's monster^mirror^alchem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>~^monster^frankenstein's monster^mirror^alchem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>~^monster^frankenstein's monster^mirror^alchem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>~^monster^frankenstein's monster^mirror^alchem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>~^monster^frankenstein's monster^mirror^alchem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6536</th>\n",
              "      <td>~^parenthood^psychodrama^human animal hybrid^b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6537</th>\n",
              "      <td>~^snow adventure^~@The sequel on the big scree...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6538</th>\n",
              "      <td>~^witch^sorceress^magic^supernatural killer^us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6539</th>\n",
              "      <td>~^pokemon^~@A story of young adults who are on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6540</th>\n",
              "      <td>~^snow^~@A thick layer of fresh snow provides ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6541 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d5c100b-6ea8-41b3-982d-c3e4581d1a53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d5c100b-6ea8-41b3-982d-c3e4581d1a53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d5c100b-6ea8-41b3-982d-c3e4581d1a53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "__w9b0uWZxc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "sBbwGYgyWejd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "RoUBeypse39O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = datasets.Dataset.from_pandas(df)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W7GxalXe33H",
        "outputId": "5d0a539e-55b5-4a2b-c68b-530ac9584c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 6541\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "muryAPT-f1ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.get_strategy()"
      ],
      "metadata": {
        "id": "0og6PURXf1ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "output = {}\n",
        "\n",
        "def tokenize_function(examples, tokenizer=tokenizer):\n",
        "\n",
        "    examples = [ex for ex in examples[\"text\"]]\n",
        "\n",
        "    output = tokenizer(\n",
        "        examples,\n",
        "        add_special_tokens=True,\n",
        "        max_length=1024,\n",
        "        truncation=True,\n",
        "        pad_to_max_length=True,\n",
        "    )\n",
        "\n",
        "    output[\"labels\"] = [x[1:] for x in output[\"input_ids\"]]\n",
        "    output[\"labels\"] = [\n",
        "        [-100 if x == tokenizer.pad_token_id else x for x in y]\n",
        "        for y in output[\"labels\"]\n",
        "    ]\n",
        "\n",
        "    output[\"input_ids\"] = [x[:-1] for x in output[\"input_ids\"]]\n",
        "    output[\"attention_mask\"] = [x[:-1] for x in output[\"attention_mask\"]]\n",
        "    return output\n",
        "\n",
        "data = data.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"],\n",
        "    load_from_cache_file=True,\n",
        ")\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "99e007af3b4d429ea1ab50b719cc0088",
            "5e917e99e95846bda4967d58384ca20d",
            "64827778c1824171a8b689e133c84eb6",
            "77e5fab1a0574064bbbff0db8385c17e",
            "5731bd1192ac4756b22096ac30af8249",
            "ba464780c7574a41a88fe63ac071edfb",
            "601ad4778bcf48f29ef6d243dbd00d8c",
            "0b7be152b2b642218b95d5e6be532f38",
            "12f8b64d25f84805ad7031cce06385a1",
            "d41c32fc5fae4b3c984ceef8480d3752",
            "4a613bb7efbc405cb60a5137d3a820ea"
          ]
        },
        "id": "r0pz7nB6fRgm",
        "outputId": "5795d68a-4b94-45a2-e227-e93d4b291fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6541 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99e007af3b4d429ea1ab50b719cc0088"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 6541\n",
            "})\n",
            "CPU times: user 25 s, sys: 580 ms, total: 25.6 s\n",
            "Wall time: 36.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.set_format(type=\"python\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "data = data.train_test_split(\n",
        "    test_size=0.1, shuffle=True, seed=1, load_from_cache_file=True\n",
        ")"
      ],
      "metadata": {
        "id": "b_Xb2DxggWtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data.save_to_disk(\"content/drive/MyDrive/gpt2_v6500_dataset_shuffle_train_test\")"
      ],
      "metadata": {
        "id": "bGSm4jaygepD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tensor_inputs = tf.convert_to_tensor(data[\"train\"][\"input_ids\"])\n",
        "train_tensor_labels = tf.convert_to_tensor(data[\"train\"][\"labels\"])\n",
        "train_tensor_mask = tf.convert_to_tensor(data[\"train\"][\"attention_mask\"])\n",
        "train = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "        {\"input_ids\": train_tensor_inputs, \"attention_mask\": train_tensor_mask},\n",
        "        train_tensor_labels,\n",
        "    )\n",
        ")\n",
        "\n",
        "test_tensor_inputs = tf.convert_to_tensor(data[\"test\"][\"input_ids\"])\n",
        "test_tensor_labels = tf.convert_to_tensor(data[\"test\"][\"labels\"])\n",
        "test_tensor_mask = tf.convert_to_tensor(data[\"test\"][\"attention_mask\"])\n",
        "test = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "        {\"input_ids\": test_tensor_inputs, \"attention_mask\": test_tensor_mask},\n",
        "        test_tensor_labels,\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9yiCoMug4ZG",
        "outputId": "b7fbc03b-1b5c-43ce-a8ee-5ca928c687b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13.9 s, sys: 917 ms, total: 14.9 s\n",
            "Wall time: 14.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model params\n",
        "BATCH_SIZE_PER_REPLICA = 2\n",
        "EPOCHS = 5\n",
        "INITAL_LEARNING_RATE = 0.001"
      ],
      "metadata": {
        "id": "rrZgLKw0vdtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
        "except NameError as e:\n",
        "    BATCH_SIZE = BATCH_SIZE_PER_REPLICA\n",
        "BUFFER_SIZE = len(train)\n",
        "\n",
        "train_ds = (\n",
        "    train.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        ")\n",
        "test_ds = test.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "uomopvGdg-qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Зниження темпу навчання\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    INITAL_LEARNING_RATE,\n",
        "    decay_steps=500,\n",
        "    decay_rate=0.7,\n",
        "    staircase=True)\n",
        "\n",
        "# ініціалізація моделі\n",
        "with strategy.scope():\n",
        "    model = TFGPT2LMHeadModel.from_pretrained(\n",
        "        \"gpt2\",\n",
        "        use_cache=False\n",
        "    )\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "    model.compile(optimizer=optimizer, loss=model.hf_compute_loss)\n",
        "\n",
        "    model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnVwUAR7hlCI",
        "outputId": "10e555a3-9cb5-4299-d24f-68f84c78f1bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tfgpt2lm_head_model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " transformer (TFGPT2MainLaye  multiple                 124439808 \n",
            " r)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124,439,808\n",
            "Trainable params: 124,439,808\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.embd_pdrop = model.config.resid_pdrop = model.config.attn_pdrop = 0.2"
      ],
      "metadata": {
        "id": "rkqjZ_Ack-Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop training when validation acc starts dropping\n",
        "# Save checkpoint of model after each period\n",
        "from datetime import datetime\n",
        "\n",
        "now = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
        "# Стоврення колбеків\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", verbose=1, patience=1, restore_best_weights=True\n",
        "    ),\n",
        "\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath= \"/content/drive/MyDrive/AI/model_checkpoints/gpt2tens_v6500/\" + now + \"_GPT2-Model_{epoch:02d}_{val_loss:.4f}.ckpt\",\n",
        "        save_weights_only=True,\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "AuQKl8ZRh6Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = '/content/drive/MyDrive/AI/model_checkpoints/gpt2tens_v6500'\n",
        "latest_checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "model.load_weights(latest_checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tVrSuS71e73",
        "outputId": "859fdf9a-e86d-44e3-ed7f-ffa10597c7da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fc7d05affd0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Тренування моделі\n",
        "steps_per_epoch = int(BUFFER_SIZE // BATCH_SIZE)\n",
        "print(\n",
        "    f\"Model Params:\\nbatch_size: {BATCH_SIZE}\\nEpochs: {EPOCHS}\\n\"\n",
        "    f\"Step p. Epoch: {steps_per_epoch}\\n\"\n",
        "    f\"Initial Learning rate: {INITAL_LEARNING_RATE}\"\n",
        ")\n",
        "hist = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1,\n",
        "    initial_epoch=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fddl4voOlPk4",
        "outputId": "2f0e06fe-ac10-4c7e-d95b-b6797453830b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Params:\n",
            "batch_size: 2\n",
            "Epochs: 5\n",
            "Step p. Epoch: 2943\n",
            "Initial Learning rate: 0.001\n",
            "Epoch 3/5\n",
            "2943/2943 [==============================] - ETA: 0s - loss: 2.4646\n",
            "Epoch 3: val_loss improved from inf to 3.35710, saving model to /content/drive/MyDrive/AI/model_checkpoints/gpt2tens_v6500/2023-05-22_1422_GPT2-Model_03_3.3571.ckpt\n",
            "2943/2943 [==============================] - 2331s 753ms/step - loss: 2.4646 - val_loss: 3.3571\n",
            "Epoch 4/5\n",
            "2943/2943 [==============================] - ETA: 0s - loss: 2.4199Restoring model weights from the end of the best epoch: 3.\n",
            "\n",
            "Epoch 4: val_loss did not improve from 3.35710\n",
            "2943/2943 [==============================] - 2202s 748ms/step - loss: 2.4199 - val_loss: 3.3662\n",
            "Epoch 4: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint_dir = '/content/drive/MyDrive/AI/model_checkpoints/gpt2tens_v6500'\n",
        "# latest_checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "# model.load_weights(latest_checkpoint_path)"
      ],
      "metadata": {
        "id": "4MROVB1YJIpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath= \"/content/drive/MyDrive/AI/model_checkpoints/gpt2tens_v6500/2023-05-20_1613_GPT2-Model_02_3.3107.ckpt\"\n",
        "# model_check = tf.train.load_checkpoint(filepath)\n",
        "# model.load_weights(model_check)"
      ],
      "metadata": {
        "id": "KG-rVuI1Nydz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"~^devil^forest^time travel^secret organization~@\""
      ],
      "metadata": {
        "id": "ebI5WS_xKVWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(\"/content/drive/MyDrive/AI/gpt2tens_model/model.h5\", save_format=\"tf\")\n",
        "model.save_pretrained(\"/content/drive/MyDrive/AI/GPT2-Fantasy/\")"
      ],
      "metadata": {
        "id": "riSRHBxPbvY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "model_test = TFGPT2LMHeadModel.from_pretrained('/content/drive/MyDrive/AI/GPT2-Fantasy/')\n",
        "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "story = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_test,\n",
        "    tokenizer=gpt_tokenizer,\n",
        "    device=0\n",
        ")"
      ],
      "metadata": {
        "id": "edptrchw7DLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8743c926-8c25-4272-eb05-35091e66dfa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/AI/gpt2tens_model2/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "story(\"~^devil^forest^time travel^secret organization~@\", temperature=1.0,\n",
        "                                max_length=128,\n",
        "                                repetition_penalty=7.0,\n",
        "                                num_beams=4, seed=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdCECNpYb2FL",
        "outputId": "0fa88f5e-1e2f-4adc-f3f1-7ba58ca35a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"~^devil^forest^time travel^secret organization~@A young man and his wife are killed in a car accident while driving across the country. Their father, who has lived for thousands of years, is convinced that he's connected to an ancient Indian deity known as Ganja. While trying to save their daughter from Ganja, they encounter many supernatural beings which have appeared over the course of centuries. One such being may be Ganja himself but it will take more than just one person to save them. In order to escape Ganja you must fight back against Ganja with your own life-or-death struggles. Can\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    }
  ]
}