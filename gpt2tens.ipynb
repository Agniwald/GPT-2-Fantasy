{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers datasets"
   ],
   "metadata": {
    "id": "-0axjXV4WZJg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hiM3zs8K6Ft"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "import pandas as pd\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "em8j8NfZY3Fu",
    "outputId": "c5b7a1fa-23f6-4c05-f766-d92fe548fd56"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"/content/drive/MyDrive/AI/plot2tag_encoded_6500.csv\", header=None, sep='\\t')\n",
    "df.columns = ['text']\n",
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "GLq_SHndZCjr",
    "outputId": "0e2c6941-a9e4-48f4-8294-15a92591093c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   text\n",
       "0     ~^monster^frankenstein's monster^mirror^alchem...\n",
       "1     ~^monster^frankenstein's monster^mirror^alchem...\n",
       "2     ~^monster^frankenstein's monster^mirror^alchem...\n",
       "3     ~^monster^frankenstein's monster^mirror^alchem...\n",
       "4     ~^monster^frankenstein's monster^mirror^alchem...\n",
       "...                                                 ...\n",
       "6536  ~^parenthood^psychodrama^human animal hybrid^b...\n",
       "6537  ~^snow adventure^~@The sequel on the big scree...\n",
       "6538  ~^witch^sorceress^magic^supernatural killer^us...\n",
       "6539  ~^pokemon^~@A story of young adults who are on...\n",
       "6540  ~^snow^~@A thick layer of fresh snow provides ...\n",
       "\n",
       "[6541 rows x 1 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-4d5c100b-6ea8-41b3-982d-c3e4581d1a53\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>~^monster^frankenstein's monster^mirror^alchem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>~^monster^frankenstein's monster^mirror^alchem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>~^monster^frankenstein's monster^mirror^alchem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>~^monster^frankenstein's monster^mirror^alchem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>~^monster^frankenstein's monster^mirror^alchem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6536</th>\n",
       "      <td>~^parenthood^psychodrama^human animal hybrid^b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6537</th>\n",
       "      <td>~^snow adventure^~@The sequel on the big scree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6538</th>\n",
       "      <td>~^witch^sorceress^magic^supernatural killer^us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6539</th>\n",
       "      <td>~^pokemon^~@A story of young adults who are on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6540</th>\n",
       "      <td>~^snow^~@A thick layer of fresh snow provides ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6541 rows \u00d7 1 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d5c100b-6ea8-41b3-982d-c3e4581d1a53')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4d5c100b-6ea8-41b3-982d-c3e4581d1a53 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4d5c100b-6ea8-41b3-982d-c3e4581d1a53');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "__w9b0uWZxc3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ],
   "metadata": {
    "id": "sBbwGYgyWejd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ],
   "metadata": {
    "id": "RoUBeypse39O"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data = datasets.Dataset.from_pandas(df)\n",
    "data"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6W7GxalXe33H",
    "outputId": "5d0a539e-55b5-4a2b-c68b-530ac9584c93"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 6541\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "muryAPT-f1ze"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "strategy = tf.distribute.get_strategy()"
   ],
   "metadata": {
    "id": "0og6PURXf1ti"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "output = {}\n",
    "\n",
    "def tokenize_function(examples, tokenizer=tokenizer):\n",
    "\n",
    "    examples = [ex for ex in examples[\"text\"]]\n",
    "\n",
    "    output = tokenizer(\n",
    "        examples,\n",
    "        add_special_tokens=True,\n",
    "        max_length=1024,\n",
    "        truncation=True,\n",
    "        pad_to_max_length=True,\n",
    "    )\n",
    "\n",
    "    output[\"labels\"] = [x[1:] for x in output[\"input_ids\"]]\n",
    "    output[\"labels\"] = [\n",
    "        [-100 if x == tokenizer.pad_token_id else x for x in y]\n",
    "        for y in output[\"labels\"]\n",
    "    ]\n",
    "\n",
    "    output[\"input_ids\"] = [x[:-1] for x in output[\"input_ids\"]]\n",
    "    output[\"attention_mask\"] = [x[:-1] for x in output[\"attention_mask\"]]\n",
    "    return output\n",
    "\n",
    "data = data.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"],\n",
    "    load_from_cache_file=True,\n",
    ")\n",
    "print(data)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176,
     "referenced_widgets": [
      "99e007af3b4d429ea1ab50b719cc0088",
      "5e917e99e95846bda4967d58384ca20d",
      "64827778c1824171a8b689e133c84eb6",
      "77e5fab1a0574064bbbff0db8385c17e",
      "5731bd1192ac4756b22096ac30af8249",
      "ba464780c7574a41a88fe63ac071edfb",
      "601ad4778bcf48f29ef6d243dbd00d8c",
      "0b7be152b2b642218b95d5e6be532f38",
      "12f8b64d25f84805ad7031cce06385a1",
      "d41c32fc5fae4b3c984ceef8480d3752",
      "4a613bb7efbc405cb60a5137d3a820ea"
     ]
    },
    "id": "r0pz7nB6fRgm",
    "outputId": "5795d68a-4b94-45a2-e227-e93d4b291fad"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/6541 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99e007af3b4d429ea1ab50b719cc0088"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 6541\n",
      "})\n",
      "CPU times: user 25 s, sys: 580 ms, total: 25.6 s\n",
      "Wall time: 36.9 s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data.set_format(type=\"python\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "data = data.train_test_split(\n",
    "    test_size=0.1, shuffle=True, seed=1, load_from_cache_file=True\n",
    ")"
   ],
   "metadata": {
    "id": "b_Xb2DxggWtK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# data.save_to_disk(\"content/drive/MyDrive/gpt2_v6500_dataset_shuffle_train_test\")"
   ],
   "metadata": {
    "id": "bGSm4jaygepD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_tensor_inputs = tf.convert_to_tensor(data[\"train\"][\"input_ids\"])\n",
    "train_tensor_labels = tf.convert_to_tensor(data[\"train\"][\"labels\"])\n",
    "train_tensor_mask = tf.convert_to_tensor(data[\"train\"][\"attention_mask\"])\n",
    "train = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        {\"input_ids\": train_tensor_inputs, \"attention_mask\": train_tensor_mask},\n",
    "        train_tensor_labels,\n",
    "    )\n",
    ")\n",
    "\n",
    "test_tensor_inputs = tf.convert_to_tensor(data[\"test\"][\"input_ids\"])\n",
    "test_tensor_labels = tf.convert_to_tensor(data[\"test\"][\"labels\"])\n",
    "test_tensor_mask = tf.convert_to_tensor(data[\"test\"][\"attention_mask\"])\n",
    "test = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        {\"input_ids\": test_tensor_inputs, \"attention_mask\": test_tensor_mask},\n",
    "        test_tensor_labels,\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x9yiCoMug4ZG",
    "outputId": "b7fbc03b-1b5c-43ce-a8ee-5ca928c687b0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 13.9 s, sys: 917 ms, total: 14.9 s\n",
      "Wall time: 14.9 s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Model params\n",
    "BATCH_SIZE_PER_REPLICA = 2\n",
    "EPOCHS = 5\n",
    "INITAL_LEARNING_RATE = 0.001"
   ],
   "metadata": {
    "id": "rrZgLKw0vdtO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "try:\n",
    "    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "except NameError as e:\n",
    "    BATCH_SIZE = BATCH_SIZE_PER_REPLICA\n",
    "BUFFER_SIZE = len(train)\n",
    "\n",
    "train_ds = (\n",
    "    train.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    ")\n",
    "test_ds = test.batch(BATCH_SIZE, drop_remainder=True)"
   ],
   "metadata": {
    "id": "uomopvGdg-qi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# \u0417\u043d\u0438\u0436\u0435\u043d\u043d\u044f \u0442\u0435\u043c\u043f\u0443 \u043d\u0430\u0432\u0447\u0430\u043d\u043d\u044f\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    INITAL_LEARNING_RATE,\n",
    "    decay_steps=500,\n",
    "    decay_rate=0.7,\n",
    "    staircase=True)\n",
    "\n",
    "# \u0456\u043d\u0456\u0446\u0456\u0430\u043b\u0456\u0437\u0430\u0446\u0456\u044f \u043c\u043e\u0434\u0435\u043b\u0456\n",
    "with strategy.scope():\n",
    "    model = TFGPT2LMHeadModel.from_pretrained(\n",
    "        \"gpt2\",\n",
    "        use_cache=False\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model.compile(optimizer=optimizer, loss=model.hf_compute_loss)\n",
    "\n",
    "    model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XnVwUAR7hlCI",
    "outputId": "10e555a3-9cb5-4299-d24f-68f84c78f1bd"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"tfgpt2lm_head_model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (TFGPT2MainLaye  multiple                 124439808 \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,439,808\n",
      "Trainable params: 124,439,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.config.embd_pdrop = model.config.resid_pdrop = model.config.attn_pdrop = 0.2"
   ],
   "metadata": {
    "id": "rkqjZ_Ack-Mt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Stop training when validation acc starts dropping\n",
    "# Save checkpoint of model after each period\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "# \u0421\u0442\u043e\u0432\u0440\u0435\u043d\u043d\u044f \u043a\u043e\u043b\u0431\u0435\u043a\u0456\u0432\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", verbose=1, patience=1, restore_best_weights=True\n",
    "    ),\n",
    "\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath= \"/content/drive/MyDrive/AI/model_checkpoints/gpt2tens_v6500/\" + now + \"_GPT2-Model_{epoch:02d}_{val_loss:.4f}.ckpt\",\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ],
   "metadata": {
    "id": "AuQKl8ZRh6Wa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "checkpoint_dir = '/content/drive/MyDrive/AI/model_checkpoints/gpt2tens_v6500'\n",
    "latest_checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "model.load_weights(latest_checkpoint_path)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1tVrSuS71e73",
    "outputId": "859fdf9a-e86d-44e3-ed7f-ffa10597c7da"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fc7d05affd0>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# \u0422\u0440\u0435\u043d\u0443\u0432\u0430\u043d\u043d\u044f \u043c\u043e\u0434\u0435\u043b\u0456\n",
    "steps_per_epoch = int(BUFFER_SIZE // BATCH_SIZE)\n",
    "print(\n",
    "    f\"Model Params:\\nbatch_size: {BATCH_SIZE}\\nEpochs: {EPOCHS}\\n\"\n",
    "    f\"Step p. Epoch: {steps_per_epoch}\\n\"\n",
    "    f\"Initial Learning rate: {INITAL_LEARNING_RATE}\"\n",
    ")\n",
    "hist = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    initial_epoch=2\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fddl4voOlPk4",
    "outputId": "2f0e06fe-ac10-4c7e-d95b-b6797453830b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Params:\n",
      "batch_size: 2\n",
      "Epochs: 5\n",
      "Step p. Epoch: 2943\n",
      "Initial Learning rate: 0.001\n",
      "Epoch 3/5\n",
      "2943/2943 [==============================] - ETA: 0s - loss: 2.4646\n",
      "Epoch 3: val_loss improved from inf to 3.35710, saving model to /content/drive/MyDrive/AI/model_checkpoints/gpt2tens_v6500/2023-05-22_1422_GPT2-Model_03_3.3571.ckpt\n",
      "2943/2943 [==============================] - 2331s 753ms/step - loss: 2.4646 - val_loss: 3.3571\n",
      "Epoch 4/5\n",
      "2943/2943 [==============================] - ETA: 0s - loss: 2.4199Restoring model weights from the end of the best epoch: 3.\n",
      "\n",
      "Epoch 4: val_loss did not improve from 3.35710\n",
      "2943/2943 [==============================] - 2202s 748ms/step - loss: 2.4199 - val_loss: 3.3662\n",
      "Epoch 4: early stopping\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# checkpoint_dir = '/content/drive/MyDrive/AI/model_checkpoints/gpt2tens_v6500'\n",
    "# latest_checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "# model.load_weights(latest_checkpoint_path)"
   ],
   "metadata": {
    "id": "4MROVB1YJIpr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "filepath= \"/content/drive/MyDrive/AI/model_checkpoints/gpt2tens_v6500/2023-05-20_1613_GPT2-Model_02_3.3107.ckpt\"\n",
    "# model_check = tf.train.load_checkpoint(filepath)\n",
    "# model.load_weights(model_check)"
   ],
   "metadata": {
    "id": "KG-rVuI1Nydz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "inp = \"~^devil^forest^time travel^secret organization~@\""
   ],
   "metadata": {
    "id": "ebI5WS_xKVWu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# model.save(\"/content/drive/MyDrive/AI/gpt2tens_model/model.h5\", save_format=\"tf\")\n",
    "model.save_pretrained(\"/content/drive/MyDrive/AI/GPT2-Fantasy/\")"
   ],
   "metadata": {
    "id": "riSRHBxPbvY3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model_test = TFGPT2LMHeadModel.from_pretrained('/content/drive/MyDrive/AI/GPT2-Fantasy/')\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "story = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_test,\n",
    "    tokenizer=gpt_tokenizer,\n",
    "    device=0\n",
    ")"
   ],
   "metadata": {
    "id": "edptrchw7DLl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8743c926-8c25-4272-eb05-35091e66dfa1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/AI/gpt2tens_model2/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "story(\"~^devil^forest^time travel^secret organization~@\", temperature=1.0,\n",
    "                                max_length=128,\n",
    "                                repetition_penalty=7.0,\n",
    "                                num_beams=4, seed=0)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdCECNpYb2FL",
    "outputId": "0fa88f5e-1e2f-4adc-f3f1-7ba58ca35a9a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'generated_text': \"~^devil^forest^time travel^secret organization~@A young man and his wife are killed in a car accident while driving across the country. Their father, who has lived for thousands of years, is convinced that he's connected to an ancient Indian deity known as Ganja. While trying to save their daughter from Ganja, they encounter many supernatural beings which have appeared over the course of centuries. One such being may be Ganja himself but it will take more than just one person to save them. In order to escape Ganja you must fight back against Ganja with your own life-or-death struggles. Can\"}]"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ]
  }
 ]
}
